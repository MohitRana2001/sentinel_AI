# Environment Configuration Template for Graph Processor VM

# ============================================
# Graph Processor VM Configuration
# ============================================
# Copy this file to /opt/sentinel_ai/backend/.env
# Replace all <PLACEHOLDER> values with your actual configuration

# ------------------
# Environment Settings
# ------------------
ENV=production
DEBUG=False

# ------------------
# Redis Configuration
# ------------------
# Redis server coordinates work distribution between services
# This should point to your centralized Redis server

REDIS_HOST=<REDIS_SERVER_IP>
# Example: REDIS_HOST=10.0.2.10
# Example: REDIS_HOST=redis.internal.example.com

REDIS_PORT=6379

REDIS_DB=0

# Redis password (leave empty if no password is set)
REDIS_PASSWORD=<REDIS_PASSWORD>
# Example: REDIS_PASSWORD=strong_redis_password_123
# Example: REDIS_PASSWORD=

# ------------------
# Redis Queue Names
# ------------------
# These MUST match the main application configuration
# Do NOT change these unless you change them everywhere

REDIS_QUEUE_GRAPH=graph_queue
# This is the only queue this VM listens to

# Reference (not used by graph processor, but kept for consistency)
REDIS_QUEUE_DOCUMENT=document_queue
REDIS_QUEUE_AUDIO=audio_queue
REDIS_QUEUE_VIDEO=video_queue

# ------------------
# Database Configuration (AlloyDB/PostgreSQL)
# ------------------
# Database stores graph metadata and job status
# This should point to your centralized database server

ALLOYDB_HOST=<ALLOYDB_SERVER_IP>
# Example: ALLOYDB_HOST=10.0.3.10
# Example: ALLOYDB_HOST=alloydb.internal.example.com

ALLOYDB_PORT=5432

ALLOYDB_USER=postgres
# Change if using a different database user

ALLOYDB_PASSWORD=<DB_PASSWORD>
# Example: ALLOYDB_PASSWORD=strong_db_password_456

ALLOYDB_DATABASE=sentinel_db
# Change if using a different database name

# ------------------
# Neo4j Configuration
# ------------------
# Neo4j stores the knowledge graph for visualization and queries
# This should point to your Neo4j server

NEO4J_URI=bolt://<NEO4J_SERVER_IP>:7687
# Example: NEO4J_URI=bolt://10.0.4.10:7687
# Example: NEO4J_URI=bolt://neo4j.internal.example.com:7687
# Use bolt:// for unencrypted, bolt+s:// for SSL/TLS

NEO4J_USERNAME=neo4j
# Default username is 'neo4j'
# Change if you've set a different username

NEO4J_PASSWORD=<NEO4J_PASSWORD>
# Example: NEO4J_PASSWORD=strong_neo4j_password_789
# IMPORTANT: Change from default 'neo4j' password immediately!

NEO4J_DATABASE=neo4j
# Default database name is 'neo4j'
# Change if using a different database (Neo4j Enterprise only)

# ------------------
# Storage Configuration
# ------------------
# Storage backend: 'gcs' for Google Cloud Storage, 'local' for filesystem
# Choose based on your infrastructure
# Graph Processor only READS from storage (no writes)

STORAGE_BACKEND=gcs
# Options: gcs, local

# GCS Configuration (if STORAGE_BACKEND=gcs)
# ------------------------------------------
GCS_BUCKET_NAME=<YOUR_BUCKET_NAME>
# Example: GCS_BUCKET_NAME=sentinel-production-bucket
# Should be the SAME bucket as Document Processor uses

GCS_PROJECT_ID=<YOUR_PROJECT_ID>
# Example: GCS_PROJECT_ID=my-gcp-project

GCS_CREDENTIALS_PATH=/opt/sentinel_ai/credentials/gcs-key.json
# Path to your service account key file
# Make sure this file exists and has proper permissions (chmod 600)

# Local Storage Configuration (if STORAGE_BACKEND=local)
# -------------------------------------------------------
LOCAL_STORAGE_PATH=/mnt/shared_storage
# Example: LOCAL_STORAGE_PATH=/mnt/nfs/sentinel_storage
# Should be the SAME path as Document Processor uses

# Alternative local storage for GCS emulation
LOCAL_GCS_STORAGE_PATH=/opt/sentinel_ai/.local_gcs
# Use this for local development/testing

# ------------------
# LLM Configuration for Graph Extraction
# ------------------
# Graph LLM extracts entities and relationships from documents
# Requires a more powerful model than document summarization
# Should point to Ollama server running a capable model (e.g., Gemma3:4b)

GRAPH_LLM_HOST=<OLLAMA_SERVER_IP>
# Example: GRAPH_LLM_HOST=10.0.7.11
# Example: GRAPH_LLM_HOST=ollama-graph.internal.example.com
# Can be same as document processor LLM or separate (separate recommended)

GRAPH_LLM_PORT=11434

GRAPH_LLM_MODEL=gemma3:4b
# Model name in Ollama
# Alternatives: llama3.2:8b, mistral:7b, gemma3:4b
# Recommendation: Use a larger model (4b-8b parameters) for better entity extraction
# Minimum: 3b parameters
# Optimal: 4b-8b parameters
# If using GPU: Can use even larger models (13b+)

# ------------------
# Graph Processing Configuration
# ------------------

# Maximum text length to send to LLM (in characters)
# Graph extraction is done in graph_processor_service.py with hardcoded 5000
# Included here for reference

# GRAPH_TEXT_MAX_CHARS=5000
# Larger text = better entity extraction but slower and more memory
# Smaller text = faster but may miss entities
# Current implementation: 5000 chars (about 1000 words)

# ------------------
# File Upload Configuration (Reference Only)
# ------------------
# These settings are used by the main application
# Included here for reference and consistency

MAX_UPLOAD_FILES=10
MAX_FILE_SIZE_MB=4
ALLOWED_EXTENSIONS=.pdf,.docx,.txt,.mp3,.wav,.mp4,.avi,.mov

# ------------------
# Development/Testing Settings
# ------------------
# Uncomment these for local development only

# USE_SQLITE_FOR_DEV=false
# SQLITE_DB_PATH=./sentinel_dev.db

# ------------------
# Notes
# ------------------
# 1. This VM needs access to:
#    - Redis (for queue operations)
#    - AlloyDB (for storing graph metadata and updating job status)
#    - Neo4j (for storing graph structure)
#    - Storage (for reading processed text files)
#    - Graph LLM (for extracting entities and relationships)
#
# 2. This VM does NOT need:
#    - Summary LLM access (document processor handles this)
#    - Embedding LLM access (document processor handles this)
#    - Direct frontend access
#    - Write access to storage (only reads)
#
# 3. Critical Dependencies:
#    - Neo4j MUST be running and accessible
#    - Graph LLM MUST have the specified model loaded
#    - Storage MUST contain files created by Document Processor
#
# 4. Security:
#    - Set file permissions: chmod 600 .env
#    - Never commit this file to Git
#    - Change default Neo4j password immediately
#    - Rotate passwords regularly
#    - Use SSL/TLS for Neo4j in production (bolt+s://)
#
# 5. Performance:
#    - Graph extraction is CPU/GPU intensive
#    - Each document takes 10-60 seconds depending on length and model
#    - LLM is the primary bottleneck
#    - GPU dramatically improves speed (3-5x)
#    - Run 2-4 workers max (more won't help due to LLM bottleneck)
#
# 6. Memory Requirements:
#    - Minimum: 16GB RAM
#    - Recommended: 32GB RAM
#    - Each worker needs ~4-8GB for LLM inference
#    - Monitor memory usage: htop or free -h
#
# 7. Scaling:
#    - Run 2-4 workers on this VM
#    - Use GPU for better throughput
#    - Consider multiple VMs only if GPU can handle it
#    - Don't over-scale (LLM becomes bottleneck)
#
# 8. Troubleshooting:
#    - Check logs: /var/log/sentinel_ai/graph-processor.log
#    - Test Neo4j: cypher-shell -a bolt://<IP>:7687 -u neo4j -p <PASSWORD>
#    - Test LLM: curl http://<OLLAMA_IP>:11434/api/tags
#    - Check queue: redis-cli LLEN graph_queue
#    - View graph in Neo4j Browser: http://<NEO4J_IP>:7474
#
# 9. Common Issues:
#    - "Neo4j not connected": Check NEO4J_URI and credentials
#    - "LLM timeout": Model may be too large or server overloaded
#    - "No graph documents generated": LLM failed to extract entities
#    - "Out of memory": Reduce number of workers or increase VM RAM
#
# 10. Monitoring:
#    - Watch queue depth: redis-cli LLEN graph_queue
#    - Monitor memory: htop
#    - Check processing rate: tail -f /var/log/sentinel_ai/graph-processor.log
#    - Neo4j admin: http://<NEO4J_IP>:7474
